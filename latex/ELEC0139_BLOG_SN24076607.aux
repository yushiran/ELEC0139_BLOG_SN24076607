\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{upadhyayAdvancesDeepLearning2024}
\citation{sushankiReviewComputationalMethods2024}
\citation{LIU2020244}
\citation{9446143}
\citation{YI2019101552}
\citation{kumarTripleClippedHistogramBased2021}
\citation{TAJBAKHSH2020101693}
\citation{TAJBAKHSH2020101693}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1} Application Domain and Challenges}{1}{section.1}\protected@file@percent }
\newlabel{sec:app_domain}{{1}{1}{Application Domain and Challenges}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1} The Application Domain: Medical Imaging}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2} Current Challenges: Data Scarcity and Its Implications}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1} Limited Annotated Datasets}{1}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2} Bias and Generalizability Issues}{1}{subsubsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3} Resource Constraints}{1}{subsubsection.1.2.3}\protected@file@percent }
\citation{vermaRoleDeepLearning2023}
\citation{zhouUNetNestedUNet2018}
\citation{9324763}
\citation{shinMedicalImageSynthesis2018}
\citation{CHAITANYA2021101934}
\citation{zhengHierarchicalSelfsupervisedLearning2021}
\citation{chenSelfsupervisedLearningMedical2019}
\citation{He2015DeepRL}
\citation{Szegedy2015RethinkingTI}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3} The Case for AI/ML Technologies}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1} Efficient Data Utilization}{2}{subsubsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2} Synthetic Data Generation}{2}{subsubsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3} Self-Supervised Learning}{2}{subsubsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2} AI/ML Solutions to Data Scarcity in Medical Imaging}{2}{section.2}\protected@file@percent }
\newlabel{sec:ml_technologies}{{2}{2}{AI/ML Solutions to Data Scarcity in Medical Imaging}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Self-Supervised Learning (SSL)}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1} Key Features of Context Restoration SSL}{2}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2} Methodology}{2}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Image Context Disordering}}{2}{algorithm.1}\protected@file@percent }
\citation{huReinforcementLearningMedical2023}
\citation{mnihHumanlevelControlDeep2015a}
\citation{Schulman2017ProximalPO}
\citation{Mnih2016AsynchronousMF}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces General CNN architecture for context restoration SSL. Blue, green, and orange strides represent convolutional, downsampling, and upsampling units, respectively.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:context_restoration_architecture}{{1}{3}{General CNN architecture for context restoration SSL. Blue, green, and orange strides represent convolutional, downsampling, and upsampling units, respectively}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of training images for self-supervised context disordering. The second column highlights swapped patches after the first iteration.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:context_disordering}{{2}{3}{Examples of training images for self-supervised context disordering. The second column highlights swapped patches after the first iteration}{figure.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3} Applications and Evaluation}{3}{subsubsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4} Benefits}{3}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} Reinforcement Learning (RL)}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1} Mathematical Formulation of Reinforcement Learning}{4}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Generic Reinforcement Learning Procedure}}{4}{algorithm.2}\protected@file@percent }
\newlabel{alg:rl_procedure}{{2}{4}{Mathematical Formulation of Reinforcement Learning}{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2} Applications of Reinforcement Learning in Medical Imaging}{4}{subsubsection.2.2.2}\protected@file@percent }
\citation{Goodfellow2014GenerativeAN}
\citation{SohlDickstein2015DeepUL}
\citation{koetzierGeneratingSyntheticData2024}
\citation{Goodfellow2014GenerativeAN}
\citation{wangGenerationSyntheticGround2022}
\citation{8099502}
\citation{He2015DeepRL}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Blue box covers image analysis tasks; green box covers anatomical sites; yellow box covers imaging modalities.}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:applications_of_rl_in_medical_imaging}{{3}{5}{Blue box covers image analysis tasks; green box covers anatomical sites; yellow box covers imaging modalities}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3} Generative Models for Medical Image Synthesis}{5}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1} Generative Adversarial Networks (GANs)}{5}{subsubsection.2.3.1}\protected@file@percent }
\citation{songScoreBasedGenerativeModeling2021}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A schematic overview of a diffusion model in training and sampling settings. In the top row, the diffusion model is trained and creates a Markov chain to add Gaussian noise to the real images, resulting in a noise vector z’. The model then reverses the Markov chain by predicting the next state of the image from the current noisy state, which is equivalent to denoising the image. During sampling (bottom row), the model can generate synthetic images by starting from a random noise vector and applying the reverse Markov chain.}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:gan_architecture}{{4}{6}{A schematic overview of a diffusion model in training and sampling settings. In the top row, the diffusion model is trained and creates a Markov chain to add Gaussian noise to the real images, resulting in a noise vector z’. The model then reverses the Markov chain by predicting the next state of the image from the current noisy state, which is equivalent to denoising the image. During sampling (bottom row), the model can generate synthetic images by starting from a random noise vector and applying the reverse Markov chain}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2} Diffusion Models}{6}{subsubsection.2.3.2}\protected@file@percent }
\citation{koetzierGeneratingSyntheticData2024}
\citation{koetzierGeneratingSyntheticData2024}
\citation{koetzierGeneratingSyntheticData2024}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Examples of synthetic ground glass nodules (GGNs), the GGNs were categorised by physicians to four categories: confidently fake, leaning fake, leaning real, and confidently real. a Synthetic GGNs classified as “real” by clinicians. b Synthetic GGNs with less convincing generated lesions (classified as “leaning fake”). c A real GGNs in the original LIDC-IDRI dataset}}{7}{figure.5}\protected@file@percent }
\newlabel{fig:gan_results}{{5}{7}{Examples of synthetic ground glass nodules (GGNs), the GGNs were categorised by physicians to four categories: confidently fake, leaning fake, leaning real, and confidently real. a Synthetic GGNs classified as “real” by clinicians. b Synthetic GGNs with less convincing generated lesions (classified as “leaning fake”). c A real GGNs in the original LIDC-IDRI dataset}{figure.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces DDPM Ancestral Sampling}}{7}{algorithm.3}\protected@file@percent }
\newlabel{alg:ddpm_sampling}{{3}{7}{Diffusion Models}{algorithm.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3} Ethical Considerations in Applying AI to Medical Imaging}{7}{section.3}\protected@file@percent }
\newlabel{sec:ethical_implications}{{3}{7}{Ethical Considerations in Applying AI to Medical Imaging}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1} Data Privacy and Security}{7}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A schematic overview of a diffusion model in training and sampling settings. In the top row, the diffusion model is trained and creates a Markov chain to add Gaussian noise to the real images, resulting in a noise vector z’. The model then reverses the Markov chain by predicting the next state of the image from the current noisy state, which is equivalent to denoising the image. During sampling (bottom row), the model can generate synthetic images by starting from a random noise vector and applying the reverse Markov chain.}}{8}{figure.6}\protected@file@percent }
\newlabel{fig:diffusion_model_architecture}{{6}{8}{A schematic overview of a diffusion model in training and sampling settings. In the top row, the diffusion model is trained and creates a Markov chain to add Gaussian noise to the real images, resulting in a noise vector z’. The model then reverses the Markov chain by predicting the next state of the image from the current noisy state, which is equivalent to denoising the image. During sampling (bottom row), the model can generate synthetic images by starting from a random noise vector and applying the reverse Markov chain}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2} Bias and Fairness}{8}{subsection.3.2}\protected@file@percent }
\citation{vermaRoleDeepLearning2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3} Transparency and Explainability}{9}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4} Accountability and Governance}{9}{subsection.3.4}\protected@file@percent }
\bibstyle{IEEEbib}
\bibdata{refs}
\bibcite{upadhyayAdvancesDeepLearning2024}{1}
\bibcite{sushankiReviewComputationalMethods2024}{2}
\bibcite{LIU2020244}{3}
\bibcite{9446143}{4}
\bibcite{YI2019101552}{5}
\bibcite{kumarTripleClippedHistogramBased2021}{6}
\bibcite{TAJBAKHSH2020101693}{7}
\bibcite{vermaRoleDeepLearning2023}{8}
\bibcite{zhouUNetNestedUNet2018}{9}
\@writefile{toc}{\contentsline {section}{\numberline {4} Conclusion}{10}{section.4}\protected@file@percent }
\newlabel{sec:conc}{{4}{10}{Conclusion}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5} References}{10}{section.5}\protected@file@percent }
\bibcite{9324763}{10}
\bibcite{shinMedicalImageSynthesis2018}{11}
\bibcite{CHAITANYA2021101934}{12}
\bibcite{zhengHierarchicalSelfsupervisedLearning2021}{13}
\bibcite{chenSelfsupervisedLearningMedical2019}{14}
\bibcite{He2015DeepRL}{15}
\bibcite{Szegedy2015RethinkingTI}{16}
\bibcite{huReinforcementLearningMedical2023}{17}
\bibcite{mnihHumanlevelControlDeep2015a}{18}
\bibcite{Schulman2017ProximalPO}{19}
\bibcite{Mnih2016AsynchronousMF}{20}
\bibcite{Goodfellow2014GenerativeAN}{21}
\bibcite{SohlDickstein2015DeepUL}{22}
\bibcite{koetzierGeneratingSyntheticData2024}{23}
\bibcite{wangGenerationSyntheticGround2022}{24}
\bibcite{8099502}{25}
\bibcite{songScoreBasedGenerativeModeling2021}{26}
\gdef \@abspage@last{12}
