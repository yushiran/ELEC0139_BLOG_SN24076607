@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}
@ARTICLE{8730517,
  author={Bhandari, Ashish Kumar and Singh, Anurag and Kumar, Immadisetty Vinod},
  journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
  title={Spatial Context Energy Curve-Based Multilevel 3-D Otsu Algorithm for Image Segmentation}, 
  year={2021},
  volume={51},
  number={5},
  pages={2760-2773},
  keywords={Image segmentation;Histograms;Color;Thresholding (Imaging);Two dimensional displays;Time complexity;Indexes;Energy curve;multilevel thresholding;One-dimensional (1-D) Otsu;segmentation;three-dimensional (3-D) Otsu;two-dimensional (2-D) Otsu},
  doi={10.1109/TSMC.2019.2916876}}
@article{upadhyayAdvancesDeepLearning2024,
  title = {Advances in {{Deep Learning Models}} for {{Resolving Medical Image Segmentation Data Scarcity Problem}}: {{A Topical Review}}},
  shorttitle = {Advances in {{Deep Learning Models}} for {{Resolving Medical Image Segmentation Data Scarcity Problem}}},
  author = {Upadhyay, Ashwini Kumar and Bhandari, Ashish Kumar},
  year = {2024},
  month = apr,
  journal = {Archives of Computational Methods in Engineering},
  volume = {31},
  number = {3},
  pages = {1701--1719},
  issn = {1886-1784},
  doi = {10.1007/s11831-023-10028-9},
  urldate = {2025-04-28},
  abstract = {Deep learning (DL) methods have recently become state-of-the-art in most automated medical image segmentation tasks. Some of the biggest challenges in this field are related to datasets. This paper aims to review the recent developments in deep learning architectures and approaches that aim to resolve dataset-related challenges faced in DL-based medical image segmentation. We have studied architectural developments in deep learning models and their recent applications in medical image segmentation tasks. Popular U-Net-based models are tested for segmentation performance comparison on a Coronavirus disease 2019 (Covid-19) lung infection Computed Tomography segmentation dataset. The comparison results prove the effectiveness of the original U-Net architecture, even in present-day medical image segmentation tasks. To overcome major dataset-related challenges such as labeled data scarcity, high annotation time and cost, distribution shifts, low-quality of images, and generalizability issues; we have studied recent developments in deep learning approaches like active learning, data augmentation, domain adaptation, and self- and semi-supervised learning, that aim to provide innovative solutions for those challenges. With rapid developments in the field, approaches like data augmentation, domain adaptation, and semi-supervised learning have become some of the hot areas of research, aiming for more efficient use of datasets, better segmentation prediction, and model generalizability.},
  langid = {english},
  keywords = {Artificial Intelligence},
  file = {F:\Zotero File\storage\VMRVZHGK\Upadhyay和Bhandari - 2024 - Advances in Deep Learning Models for Resolving Medical Image Segmentation Data Scarcity Problem A T.pdf}
}
@article{sushankiReviewComputationalMethods2024,
  title = {A {{Review}} on {{Computational Methods}} for {{Breast Cancer Detection}} in {{Ultrasound Images Using Multi-Image Modalities}}},
  author = {Sushanki, Sushi and Bhandari, Ashish Kumar and Singh, Amit Kumar},
  year = {2024},
  month = apr,
  journal = {Archives of Computational Methods in Engineering},
  volume = {31},
  number = {3},
  pages = {1277--1296},
  issn = {1886-1784},
  doi = {10.1007/s11831-023-10015-0},
  urldate = {2025-04-28},
  abstract = {Breast cancer is a kind of cancer that develops and propagates from tissues of the breast and slowly transcends the whole body, this type of tumor is found in both sexes. Early detection of this disease is very important as at this stage it can be controlled by giving patients the required treatment and their valuable life can be saved. Researchers and scientists according to various studies have found methods to detect cancer at the initial stages, however, misperception in identifying skeptical lesions can be due to poor image quality and diverse breast density. Breast cancer (BC) is still a major concern for world health, necessitating ongoing innovation in early diagnosis and detection. Breast cancer diagnosis has made significant strides in recent years, especially with the incorporation of multi-modal imaging modalities. This article provides a summary of the most recent methods and advancements in multi-modal imaging for the detection of breast cancer. When radiomics, a quantitative study of imaging data, is integrated with machine learning and deep learning algorithms, breast lesions have demonstrated potential. These techniques can help distinguish between benign and malignant tumours, providing physicians with crucial information.At various phases of breast cancer detection, new methods have been developed for enhancement, segmentation, feature extraction, and classification employing multiple picture modalities. This review paper`s objective is to represent all prior research in the area of breast cancer categorization utilising many imaging modalities. This paper provides a thorough and rigorous examination of current trends in the field of BC detection and classification.},
  langid = {english},
  file = {F:\Zotero File\storage\8EDLU98K\Sushanki 等 - 2024 - A Review on Computational Methods for Breast Cancer Detection in Ultrasound Images Using Multi-Image.pdf}
}
@article{LIU2020244,
  title = {A Survey on {{U-shaped}} Networks in Medical Image Segmentations},
  author = {Liu, Liangliang and Cheng, Jianhong and Quan, Quan and Wu, Fang-Xiang and Wang, Yu-Ping and Wang, Jianxin},
  year = {2020},
  journal = {Neurocomputing},
  volume = {409},
  pages = {244--258},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.05.070},
  abstract = {The U-shaped network is one of the end-to-end convolutional neural networks (CNNs). In electron microscope segmentation of ISBI challenge 2012, the concise architecture and outstanding performance of the U-shaped network are impressive. Then, a variety of segmentation models based on this architecture have been proposed for medical image segmentations. We present a comprehensive literature review of U-shaped networks applied to medical image segmentation tasks, focusing on the architectures, extended mechanisms and application areas in these studies. The aim of this survey is twofold. First, we report the different extended U-shaped networks, discuss main state-of-the-art extended mechanisms, including residual mechanism, dense mechanism, dilated mechanism, attention mechanism, multi-module mechanism, and ensemble mechanism, analyze their pros and cons. Second, this survey provides the overview of studies in main application areas of U-shaped networks, including brain tumor, stroke, white matter hyperintensities (WMHs), eye, cardiac, liver, musculoskeletal, skin cancer, and neuronal pathology. Finally, we summarize the current U-shaped networks, point out the open challenges and directions for future research.},
  keywords = {Convolutional neural networks,Extended mechanism,Medical image segmentation,U-shaped network}
}
@ARTICLE{9446143,
  author={Siddique, Nahian and Paheding, Sidike and Elkin, Colin P. and Devabhaktuni, Vijay},
  journal={IEEE Access}, 
  title={U-Net and Its Variants for Medical Image Segmentation: A Review of Theory and Applications}, 
  year={2021},
  volume={9},
  number={},
  pages={82031-82057},
  keywords={Image segmentation;Convolution;Biomedical imaging;Three-dimensional displays;Logic gates;Deep learning;Computer architecture;Biomedical imaging;deep learning;neural network architecture;segmentation;U-net},
  doi={10.1109/ACCESS.2021.3086020}}
@article{YI2019101552,
  title = {Generative Adversarial Network in Medical Imaging: {{A}} Review},
  author = {Yi, Xin and Walia, Ekta and Babyn, Paul},
  year = {2019},
  journal = {Medical Image Analysis},
  volume = {58},
  pages = {101552},
  issn = {1361-8415},
  doi = {10.1016/j.media.2019.101552},
  abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
  keywords = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review}
}
@article{kumarTripleClippedHistogramBased2021,
  title = {Triple {{Clipped Histogram-Based Medical Image Enhancement Using Spatial Frequency}}},
  author = {Kumar, Sonu and Bhandari, Ashish Kumar and Raj, Aditya and Swaraj, Kirti},
  year = {2021},
  month = jul,
  journal = {IEEE transactions on nanobioscience},
  volume = {20},
  number = {3},
  pages = {278--286},
  issn = {1558-2639},
  doi = {10.1109/TNB.2021.3064077},
  abstract = {In this paper, a novel triple clipped histogram model-based fusion approach has been proposed to improve the basics features, brightness preservation and contrast of the medical images. This incorporates the features of the equalized image and input image together. In the initial step, the low-contrast medical image is equalized using the triple clipped dynamic histogram equalization technique for which the histogram of the input medical image is split into three sections on the basis of standard deviation with almost equal number of pixels. The clipping process of the histogram is performed on every histogram section and mapped to a new dynamic range using simple calculations. In the second step, the sub-histogram equalization process is performed separately. Approximation and detail coefficients of equalized and input images are separated using discrete wavelet transform (DWT). Thereafter, the approximation coefficients are modified using some basic calculation-based fusion which involves singular value decomposition (SVD) and its inverse. Detail coefficients are fused using spatial frequency features. This yields modified approximation and detail coefficients for an enhanced image. Finally, inverse discrete wavelet transform (IDWT) has been applied to the modified coefficients which result in an enhanced image with improved visual quality. These improvements are analyzed qualitatively and quantitatively.},
  langid = {english},
  pmid = {33661735},
  keywords = {Algorithms,Image Enhancement,Wavelet Analysis}
}
@article{TAJBAKHSH2020101693,
  title = {Embracing Imperfect Datasets: {{A}} Review of Deep Learning Solutions for Medical Image Segmentation},
  author = {Tajbakhsh, Nima and Jeyaseelan, Laura and Li, Qian and Chiang, Jeffrey N. and Wu, Zhihao and Ding, Xiaowei},
  year = {2020},
  journal = {Medical Image Analysis},
  volume = {63},
  pages = {101693},
  issn = {1361-8415},
  doi = {10.1016/j.media.2020.101693},
  abstract = {The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions. We hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets.},
  keywords = {And weak annotations,Imperfect dataset,Medical image segmentation,Noisy annotations,Scarce annotations,Sparse annotations,Unreliable annotations}
}
@article{vermaRoleDeepLearning2023,
  title = {Role of {{Deep Learning}} in {{Classification}} of {{Brain MRI Images}} for {{Prediction}} of {{Disorders}}: {{A Survey}} of {{Emerging Trends}}},
  shorttitle = {Role of {{Deep Learning}} in {{Classification}} of {{Brain MRI Images}} for {{Prediction}} of {{Disorders}}},
  author = {Verma, Poonam Rani and Bhandari, Ashish Kumar},
  year = {2023},
  month = nov,
  journal = {Archives of Computational Methods in Engineering},
  volume = {30},
  number = {8},
  pages = {4931--4957},
  issn = {1886-1784},
  doi = {10.1007/s11831-023-09967-0},
  urldate = {2025-04-29},
  abstract = {Image classification is the act of labeling groups of pixels or voxels of an image based on some rules. It finds applications in medical image analysis, and satellite image identification, along with others. Numerous studies are present in the literature where the classification is done after segmentation especially in medical images to extract only necessary areas and thereby classify them based on some criteria. It finds applications in the detection of disorders and detailed study of a particular human organ of interest. In this regard, it is important to know the challenges in this field, for accurate segmentation and classification of the region of interest. Recently, deep learning (DL) based methods for the same are being used because of higher performance as compared to the handcrafted features. Increased performance comes with various challenges like complexity, the requirement of a large amount of data, and so on. This study provides a comprehensive review of issues related to recent works on segmentation and classification techniques. This review also discusses the gaps in the literature not discussed so far and put a contributed viewpoint on the same along with future directions. It will also compare and relate each work with another and examine the datasets used along with the parametric metrics and the challenges in their use. The main focus of this review is an object-based classification used in medical imagery. It is estimated that this study will address the recent challenges and provides insights into the suggestions on different types of methods being used in the current decade.},
  langid = {english},
  keywords = {Artificial Intelligence},
  file = {F:\Zotero File\storage\AH5V6WSW\Verma和Bhandari - 2023 - Role of Deep Learning in Classification of Brain MRI Images for Prediction of Disorders A Survey of.pdf}
}
@inproceedings{zhouUNetNestedUNet2018,
  title = {{{UNet}}++: {{A Nested U-Net Architecture}} for {{Medical Image Segmentation}}},
  shorttitle = {{{UNet}}++},
  booktitle = {Deep {{Learning}} in {{Medical Image Analysis}} and {{Multimodal Learning}} for {{Clinical Decision Support}}},
  author = {Zhou, Zongwei and Rahman Siddiquee, Md Mahfuzur and Tajbakhsh, Nima and Liang, Jianming},
  editor = {Stoyanov, Danail and Taylor, Zeike and Carneiro, Gustavo and {Syeda-Mahmood}, Tanveer and Martel, Anne and {Maier-Hein}, Lena and Tavares, Jo{\~a}o Manuel R.S. and Bradley, Andrew and Papa, Jo{\~a}o Paulo and Belagiannis, Vasileios and Nascimento, Jacinto C. and Lu, Zhi and Conjeti, Sailesh and Moradi, Mehdi and Greenspan, Hayit and Madabhushi, Anant},
  year = {2018},
  pages = {3--11},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-00889-5_1},
  abstract = {In this paper, we present UNet++, a new, more powerful architecture for medical image segmentation. Our architecture is essentially a deeply-supervised encoder-decoder network where the encoder and decoder sub-networks are connected through a series of nested, dense skip pathways. The re-designed skip pathways aim at reducing the semantic gap between the feature maps of the encoder and decoder sub-networks. We argue that the optimizer would deal with an easier learning task when the feature maps from the decoder and encoder networks are semantically similar. We have evaluated UNet++ in comparison with U-Net and wide U-Net architectures across multiple medical image segmentation tasks: nodule segmentation in the low-dose CT scans of chest, nuclei segmentation in the microscopy images, liver segmentation in abdominal CT scans, and polyp segmentation in colonoscopy videos. Our experiments demonstrate that UNet++ with deep supervision achieves an average IoU gain of 3.9 and 3.4 points over U-Net and wide U-Net, respectively.},
  isbn = {978-3-030-00889-5},
  langid = {english},
  file = {F:\Zotero File\storage\U2MPGVH9\Zhou 等 - 2018 - UNet++ A Nested U-Net Architecture for Medical Image Segmentation.pdf}
}
@ARTICLE{9324763,
  author={Gilbert, Andrew and Marciniak, Maciej and Rodero, Cristobal and Lamata, Pablo and Samset, Eigil and Mcleod, Kristin},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Generating Synthetic Labeled Data From Existing Anatomical Models: An Example With Echocardiography Segmentation}, 
  year={2021},
  volume={40},
  number={10},
  pages={2783-2794},
  keywords={Pipelines;Image segmentation;Task analysis;Ultrasonic imaging;Shape;Annotations;Labeling;Data generation;echocardiography;generative adversarial networks;segmentation;synthesis},
  doi={10.1109/TMI.2021.3051806}}
@inproceedings{shinMedicalImageSynthesis2018,
  title = {Medical {{Image Synthesis}} for {{Data Augmentation}} and {{Anonymization Using Generative Adversarial Networks}}},
  booktitle = {Simulation and {{Synthesis}} in {{Medical Imaging}}},
  author = {Shin, Hoo-Chang and Tenenholtz, Neil A. and Rogers, Jameson K. and Schwarz, Christopher G. and Senjem, Matthew L. and Gunter, Jeffrey L. and Andriole, Katherine P. and Michalski, Mark},
  editor = {Gooya, Ali and Goksel, Orcun and Oguz, Ipek and Burgos, Ninon},
  year = {2018},
  pages = {1--11},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-00536-8_1},
  abstract = {Data diversity is critical to success when training deep learning models. Medical imaging data sets are often imbalanced as pathologic findings are generally rare, which introduces significant challenges when training deep learning models. In this work, we propose a method to generate synthetic abnormal MRI images with brain tumors by training a generative adversarial network using two publicly available data sets of brain MRI. We demonstrate two unique benefits that the synthetic images provide. First, we illustrate improved performance on tumor segmentation by leveraging the synthetic images as a form of data augmentation. Second, we demonstrate the value of generative models as an anonymization tool, achieving comparable tumor segmentation results when trained on the synthetic data versus when trained on real subject data. Together, these results offer a potential solution to two of the largest challenges facing machine learning in medical imaging, namely the small incidence of pathological findings, and the restrictions around sharing of patient data.},
  isbn = {978-3-030-00536-8},
  langid = {english},
  keywords = {Brain tumor,Deep learning,GAN,Generative models,Image synthesis,Magnetic resonance imaging,MRI,Segmentation},
  file = {F:\Zotero File\storage\W2AMWXXU\Shin 等 - 2018 - Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Network.pdf}
}
@article{CHAITANYA2021101934,
  title = {Semi-Supervised Task-Driven Data Augmentation for Medical Image Segmentation},
  author = {Chaitanya, Krishna and Karani, Neerav and Baumgartner, Christian F. and Erdil, Ertunc and Becker, Anton and Donati, Olivio and Konukoglu, Ender},
  year = {2021},
  journal = {Medical Image Analysis},
  volume = {68},
  pages = {101934},
  issn = {1361-8415},
  doi = {10.1016/j.media.2020.101934},
  abstract = {Supervised learning-based segmentation methods typically require a large number of annotated training data to generalize well at test time. In medical applications, curating such datasets is not a favourable option because acquiring a large number of annotated samples from experts is time-consuming and expensive. Consequently, numerous methods have been proposed in the literature for learning with limited annotated examples. Unfortunately, the proposed approaches in the literature have not yet yielded significant gains over random data augmentation for image segmentation, where random augmentations themselves do not yield high accuracy. In this work, we propose a novel task-driven data augmentation method for learning with limited labeled data where the synthetic data generator, is optimized for the segmentation task. The generator of the proposed method models intensity and shape variations using two sets of transformations, as additive intensity transformations and deformation fields. Both transformations are optimized using labeled as well as unlabeled examples in a semi-supervised framework. Our experiments on three medical datasets, namely cardiac, prostate and pancreas, show that the proposed approach significantly outperforms standard augmentation and semi-supervised approaches for image segmentation in the limited annotation setting. The code is made publicly available at https://github.com/krishnabits001/task\_driven\_data\_augmentation.},
  keywords = {Data augmentation,Deep learning,Machine learning,Medical image segmentation,Semi-supervised learning}
}
@inproceedings{zhengHierarchicalSelfsupervisedLearning2021,
  title = {Hierarchical {{Self-supervised Learning}} for {{Medical Image Segmentation Based}} on {{Multi-domain Data Aggregation}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} -- {{MICCAI}} 2021},
  author = {Zheng, Hao and Han, Jun and Wang, Hongxiao and Yang, Lin and Zhao, Zhuo and Wang, Chaoli and Chen, Danny Z.},
  editor = {{de Bruijne}, Marleen and Cattin, Philippe C. and Cotin, St{\'e}phane and Padoy, Nicolas and Speidel, Stefanie and Zheng, Yefeng and Essert, Caroline},
  year = {2021},
  pages = {622--632},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-87193-2_59},
  abstract = {A large labeled dataset is a key to the success of supervised deep learning, but for medical image segmentation, it is highly challenging to obtain sufficient annotated images for model training. In many scenarios, unannotated images are abundant and easy to acquire. Self-supervised learning (SSL) has shown great potentials in exploiting raw data information and representation learning. In this paper, we propose Hierarchical Self-Supervised Learning (HSSL), a new self-supervised framework that boosts medical image segmentation by making good use of unannotated data. Unlike the current literature on task-specific self-supervised pretraining followed by supervised fine-tuning, we utilize SSL to learn task-agnostic knowledge from heterogeneous data for various medical image segmentation tasks. Specifically, we first aggregate a dataset from several medical challenges, then pre-train the network in a self-supervised manner, and finally fine-tune on labeled data. We develop a new loss function by combining contrastive loss and classification loss, and pre-train an encoder-decoder architecture for segmentation tasks. Our extensive experiments show that multi-domain joint pre-training benefits downstream segmentation tasks and outperforms single-domain pre-training significantly. Compared to learning from scratch, our method yields better performance on various tasks (e.g., \$\$+0.69{\textbackslash}\%\$\$+0.69\%to \$\$+18.60{\textbackslash}\%\$\$+18.60\%in Dice with \$\$5{\textbackslash}\%\$\$5\%of annotated data). With limited amounts of training data, our method can substantially bridge the performance gap with respect to denser annotations (e.g., \$\$10{\textbackslash}\%\$\$10\%vs.~\$\$100{\textbackslash}\%\$\$100\%annotations).},
  isbn = {978-3-030-87193-2},
  langid = {english},
  keywords = {Image segmentation,Multi-domain,Self-supervised learning},
  file = {F:\Zotero File\storage\DK6HJY7J\Zheng 等 - 2021 - Hierarchical Self-supervised Learning for Medical Image Segmentation Based on Multi-domain Data Aggr.pdf}
}
@article{chenSelfsupervisedLearningMedical2019,
  title = {Self-Supervised Learning for Medical Image Analysis Using Image Context Restoration},
  author = {Chen, Liang and Bentley, Paul and Mori, Kensaku and Misawa, Kazunari and Fujiwara, Michitaka and Rueckert, Daniel},
  year = {2019},
  month = dec,
  journal = {Medical Image Analysis},
  volume = {58},
  pages = {101539},
  issn = {1361-8415},
  doi = {10.1016/j.media.2019.101539},
  urldate = {2025-04-29},
  abstract = {Machine learning, particularly deep learning has boosted medical image analysis over the past years. Training a good model based on deep learning requires large amount of labelled data. However, it is often difficult to obtain a sufficient number of labelled images for training. In many scenarios the dataset in question consists of more unlabelled images than labelled ones. Therefore, boosting the performance of machine learning models by using unlabelled as well as labelled data is an important but challenging problem. Self-supervised learning presents one possible solution to this problem. However, existing self-supervised learning strategies applicable to medical images cannot result in significant performance improvement. Therefore, they often lead to only marginal improvements. In this paper, we propose a novel self-supervised learning strategy based on context restoration in order to better exploit unlabelled images. The context restoration strategy has three major features: 1) it learns semantic image features; 2) these image features are useful for different types of subsequent image analysis tasks; and 3) its implementation is simple. We validate the context restoration strategy in three common problems in medical imaging: classification, localization, and segmentation. For classification, we apply and test it to scan plane detection in fetal 2D ultrasound images; to localise abdominal organs in CT images; and to segment brain tumours in multi-modal MR images. In all three cases, self-supervised learning based on context restoration learns useful semantic features and lead to improved machine learning models for the above tasks.},
  langid = {english},
  keywords = {Context restoration,Medical image analysis,Self-supervised learning},
  file = {F\:\\Zotero File\\storage\\7K6B54HG\\Chen 等 - 2019 - Self-supervised learning for medical image analysis using image context restoration.pdf;F\:\\Zotero File\\storage\\Q7GH94AX\\S1361841518304699.html}
}
@article{He2015DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={770-778},
  url={https://api.semanticscholar.org/CorpusID:206594692}
}
@article{Szegedy2015RethinkingTI,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Zbigniew Wojna},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015},
  pages={2818-2826},
  url={https://api.semanticscholar.org/CorpusID:206593880}
}
@article{huReinforcementLearningMedical2023,
  title = {Reinforcement Learning in Medical Image Analysis: {{Concepts}}, Applications, Challenges, and Future Directions},
  shorttitle = {Reinforcement Learning in Medical Image Analysis},
  author = {Hu, Mingzhe and Zhang, Jiahan and Matkovic, Luke and Liu, Tian and Yang, Xiaofeng},
  year = {2023},
  journal = {Journal of Applied Clinical Medical Physics},
  volume = {24},
  number = {2},
  pages = {e13898},
  issn = {1526-9914},
  doi = {10.1002/acm2.13898},
  urldate = {2025-04-29},
  abstract = {Motivation Medical image analysis involves a series of tasks used to assist physicians in qualitative and quantitative analyses of lesions or anatomical structures which can significantly improve the accuracy and reliability of medical diagnoses and prognoses. Traditionally, these tedious tasks were finished by experienced physicians or medical physicists and were marred with two major problems, low efficiency and bias. In the past decade, many machine learning methods have been applied to accelerate and automate the image analysis process. Compared to the enormous deployments of supervised and unsupervised learning models, attempts to use reinforcement learning in medical image analysis are still scarce. We hope that this review article could serve as the stepping stone for related research in the future. Significance We found that although reinforcement learning has gradually gained momentum in recent years, many researchers in the medical analysis field still find it hard to understand and deploy in clinical settings. One possible cause is a lack of well-organized review articles intended for readers without professional computer science backgrounds. Rather than to provide a comprehensive list of all reinforcement learning models applied in medical image analysis, the aim of this review is to help the readers formulate and solve their medical image analysis research through the lens of reinforcement learning. Approach \& Results We selected published articles from Google Scholar and PubMed. Considering the scarcity of related articles, we also included some outstanding newest preprints. The papers were carefully reviewed and categorized according to the type of image analysis task. In this article, we first reviewed the basic concepts and popular models of reinforcement learning. Then, we explored the applications of reinforcement learning models in medical image analysis. Finally, we concluded the article by discussing the reviewed reinforcement learning approaches' limitations and possible future improvements.},
  copyright = {{\copyright} 2023 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals, LLC on behalf of The American Association of Physicists in Medicine.},
  langid = {english},
  keywords = {learning,reinforcement},
  file = {F\:\\Zotero File\\storage\\BLZ6DEM3\\Hu 等 - 2023 - Reinforcement learning in medical image analysis Concepts, applications, challenges, and future dir.pdf;F\:\\Zotero File\\storage\\MRFDFJKJ\\acm2.html}
}
@article{mnihHumanlevelControlDeep2015a,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  month = feb,
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  issn = {1476-4687},
  doi = {10.1038/nature14236},
  abstract = {An artificial agent is developed that learns to play~a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a~performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.}
}
@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347},
  url={https://api.semanticscholar.org/CorpusID:28695052}
}
@inproceedings{Mnih2016AsynchronousMF,
  title={Asynchronous Methods for Deep Reinforcement Learning},
  author={Volodymyr Mnih and Adri{\`a} Puigdom{\`e}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  booktitle={International Conference on Machine Learning},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:6875312}
}
@article{koetzierGeneratingSyntheticData2024,
  title = {Generating {{Synthetic Data}} for {{Medical Imaging}}},
  author = {Koetzier, Lennart R. and Wu, Jie and Mastrodicasa, Domenico and Lutz, Aline and Chung, Matthew and Koszek, W. Adam and Pratap, Jayanth and Chaudhari, Akshay S. and Rajpurkar, Pranav and Lungren, Matthew P. and Willemink, Martin J.},
  year = {2024},
  month = sep,
  journal = {Radiology},
  volume = {312},
  number = {3},
  pages = {e232471},
  publisher = {Radiological Society of North America},
  issn = {0033-8419},
  doi = {10.1148/radiol.232471},
  urldate = {2025-04-29},
  abstract = {Artificial intelligence (AI) models for medical imaging tasks, such as classification or segmentation, require large and diverse datasets of images. However, due to privacy and ethical issues, as well as data sharing infrastructure barriers, these datasets are scarce and difficult to assemble. Synthetic medical imaging data generated by AI from existing data could address this challenge by augmenting and anonymizing real imaging data. In addition, synthetic data enable new applications, including modality translation, contrast synthesis, and professional training for radiologists. However, the use of synthetic data also poses technical and ethical challenges. These challenges include ensuring the realism and diversity of the synthesized images while keeping data unidentifiable, evaluating the performance and generalizability of models trained on synthetic data, and high computational costs. Since existing regulations are not sufficient to guarantee the safe and ethical use of synthetic images, it becomes evident that updated laws and more rigorous oversight are needed. Regulatory bodies, physicians, and AI developers should collaborate to develop, maintain, and continually refine best practices for synthetic data. This review aims to provide an overview of the current knowledge of synthetic data in medical imaging and highlights current key challenges in the field to guide future research and development. {\copyright} RSNA, 2024},
  langid = {english},
  file = {F:\Zotero File\storage\8XW3XVTD\Koetzier 等 - 2024 - Generating Synthetic Data for Medical Imaging.pdf}
}
@inproceedings{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Nets},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  booktitle={Neural Information Processing Systems},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:261560300}
}
@article{SohlDickstein2015DeepUL,
  title={Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author={Jascha Narain Sohl-Dickstein and Eric A. Weiss and Niru Maheswaranathan and Surya Ganguli},
  journal={ArXiv},
  year={2015},
  volume={abs/1503.03585},
  url={https://api.semanticscholar.org/CorpusID:14888175}
}
@article{wangGenerationSyntheticGround2022,
  title = {Generation of Synthetic Ground Glass Nodules Using Generative Adversarial Networks ({{GANs}})},
  author = {Wang, Zhixiang and Zhang, Zhen and Feng, Ying and Hendriks, Lizza E. L. and Miclea, Razvan L. and Gietema, Hester and Schoenmaekers, Janna and Dekker, Andre and Wee, Leonard and Traverso, Alberto},
  year = {2022},
  month = nov,
  journal = {European Radiology Experimental},
  volume = {6},
  number = {1},
  pages = {59},
  issn = {2509-9280},
  doi = {10.1186/s41747-022-00311-y},
  urldate = {2025-04-29},
  abstract = {Data shortage is a common challenge in developing computer-aided diagnosis systems. We developed a generative adversarial network (GAN) model to generate synthetic lung lesions mimicking ground glass nodules (GGNs).},
  langid = {english},
  keywords = {Deep learning,Lung,Neural networks (computer),Solitary pulmonary nodule,Tomography (x-ray computed)},
  file = {F\:\\Zotero File\\storage\\3KTPPIS3\\Wang 等 - 2022 - Generation of synthetic ground glass nodules using generative adversarial networks (GANs).pdf;F\:\\Zotero File\\storage\\MKCKQPDK\\s41747-022-00311-y.html}
}
@INPROCEEDINGS{8099502,
  author={Ledig, Christian and Theis, Lucas and Huszár, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 
  year={2017},
  volume={},
  number={},
  pages={105-114},
  keywords={Image resolution;Signal resolution;Gallium nitride;Image reconstruction;Manifolds;Training;Network architecture},
  doi={10.1109/CVPR.2017.19}}
@misc{songScoreBasedGenerativeModeling2021,
  title = {Score-{{Based Generative Modeling}} through {{Stochastic Differential Equations}}},
  author = {Song, Yang and {Sohl-Dickstein}, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  year = {2021},
  month = feb,
  number = {arXiv:2011.13456},
  eprint = {2011.13456},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2011.13456},
  urldate = {2025-04-30},
  abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field ({\textbackslash}aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {F\:\\Zotero File\\storage\\D9DXCM7I\\Song 等 - 2021 - Score-Based Generative Modeling through Stochastic Differential Equations.pdf;F\:\\Zotero File\\storage\\WLZD9W66\\2011.html}
}
